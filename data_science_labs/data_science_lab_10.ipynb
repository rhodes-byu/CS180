{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPir_6bCCFnZ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhodes-byu/CS180/blob/main/data_science_labs/data_science_lab_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><p><b>After clicking the \"Open in Colab\" link, copy the notebook to your own Google Drive before getting started, or it will not save your work</b></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_slaQdUGCB0t"
      },
      "source": [
        "# BYU CS 180 Lab 10: Machine Learning with Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gaema31vjP8f"
      },
      "outputs": [],
      "source": [
        "# Dependencies for the lab\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct7fnkcnCL8O"
      },
      "source": [
        "## Introduction:\n",
        "Introduction:\n",
        "Scikit-learn is a very popular library for machine learning in Python. You can think of it as an add-on to scipy/numpy with a very large number of implementations of common machine learning algorithms.\n",
        "\n",
        "In general, the scikit-learn API can help you accomplish the following tasks:\n",
        "* Preprocessing\n",
        "* Dimensionality Reduction\n",
        "* Clustering\n",
        "* Classification\n",
        "* Regression\n",
        "\n",
        "Lab Objective:\n",
        "\n",
        "Learn and become proficient at using different machine learning algorithms in the Scikit-Learn tool set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFEf3q_MDWof"
      },
      "source": [
        "For this lab you will need to create a number of plots where each point is given a different color. You can do this using matplotlib. The basic idea is you can create an array of colors and an array of indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FT2XuQCDcPE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "colors = np.array(['red', 'green', 'blue', 'yellow'])\n",
        "\n",
        "n = 25\n",
        "\n",
        "x1 = np.random.multivariate_normal([10, 10], cov=np.eye(2), size=n)\n",
        "x1_idx = np.zeros(n, dtype=int)\n",
        "\n",
        "x2 = np.random.multivariate_normal([0, 0], cov=np.array([[5, 0], [0, 1]]), size=n)\n",
        "x2_idx = np.ones(n, dtype=int)\n",
        "\n",
        "X = np.concatenate([x1, x2], axis=0)\n",
        "X_idx = np.concatenate([x1_idx, x2_idx])\n",
        "\n",
        "# create the plot and index into the colors array\n",
        "plt.scatter(X[:, 0], X[:, 1], c=colors[X_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfgGOWBMDPRn"
      },
      "source": [
        "## Exercise 1: Clusters!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv-ooFEODsDR"
      },
      "source": [
        "In this exercise, you will train three different clustering algorithms on three different datasets. \n",
        "\n",
        "### Algorithms:\n",
        "#### K-means \n",
        "* [Overview](https://scikit-learn.org/stable/modules/clustering.html#k-means)\n",
        "* [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)\n",
        "\n",
        "#### DBScan: \n",
        "\n",
        "* [Overview](https://scikit-learn.org/stable/modules/clustering.html#dbscan)\n",
        "* [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN)\n",
        "\n",
        "#### GMM: \n",
        "\n",
        "* [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)\n",
        "\n",
        "After reading the above documentation (You can skim it) attempt to explain to me like I'm five, what these algorithms are doing:\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXD4Wq0YE7dJ"
      },
      "source": [
        "Explain how K-Means works?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1MQ-VVXE-DF"
      },
      "source": [
        "(Enter Answer Here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8BlEMR0FBOq"
      },
      "source": [
        "Explain how DBScan works?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZulwiVmFFZ1"
      },
      "source": [
        "(Enter Answer Here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onSvVXlZFGPO"
      },
      "source": [
        "Explain how GMM works?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB_lFN6DFH5N"
      },
      "source": [
        "(Enter Answer Here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-PO4i3CFRsA"
      },
      "source": [
        "#### Datasets:\n",
        "We will generate three toy datasets using the scikit-learn api, which you can do with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_mg-V-WFT9D"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "np.random.seed(0)\n",
        "\n",
        "# ============\n",
        "# Generate datasets. We choose the size big enough to see the scalability\n",
        "# of the algorithms, but not too big to avoid too long running times\n",
        "# ============\n",
        "n_samples = 1500\n",
        "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=0.05)[0]\n",
        "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=0.05)[0]\n",
        "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58jiA8OxFaIW"
      },
      "source": [
        "This generates three datasets, `noisy_circles`, `noisy_moons`, and `blobs`\n",
        "\n",
        "Your Task: \n",
        "* We want you to train each clustering algorithm on each dataset (you should have a total of 9 plots).\n",
        "* For each dataset/algorithm, plot the points. Color the points using the cluster the belong to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkQd_rCFFZOR"
      },
      "outputs": [],
      "source": [
        "#Enter the code for exercise 1 here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj_3PLo6GEbk"
      },
      "source": [
        "## Exercise 2: Flower Power Returns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO2e41faGJon"
      },
      "source": [
        "In the previous exercise we looked simple datasets with 2 dimensions (features). In real life, we often have many more variables than. Clustering algorithms can also be applied to higher dimensional data. For this exercise train k-means on the Iris dataset, which has 4 dimensions (features). This is difficult visualize so we will also apply a dimensionality technique to the data to reduce to 2-D strictly to create a plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzt97qy5GNeN"
      },
      "source": [
        "### Dataset\n",
        "Download the iris dataset and cast to a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBmx23BaGQRU"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "df = sm.datasets.get_rdataset(dataname='iris', package='datasets').data\n",
        "X = df.iloc[:, :4].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMl4fYyOGSEC"
      },
      "source": [
        "We know the iris dataset has three classes `['setosa', 'versicolor', 'virginica']`\n",
        "\n",
        "Your Task: \n",
        "* Train K-means on the iris dataset with 3 clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ4NYtglGZCH"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "# your code goes here\n",
        "# clusters = get predicted clusters indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWpEzfzdGlgB"
      },
      "source": [
        "Now letâ€™s visualize the clusters by reducing the feature space to 2-D. This will allow us to create a plot. We will use T-distributed Stochastic Neighbor Embedding [sklearn.manifold.TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXAebx_1Gk1D"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(n_components=2)\n",
        "X_reduced = tsne.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv2vEMnEGwpA"
      },
      "source": [
        "Your Task:\n",
        "* Create a plot using X_reduced, where each point is colored according to its cluster id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqHh8YtQG5cz"
      },
      "outputs": [],
      "source": [
        "#Enter your code for the X_reduced plot here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVbB2FMFG9en"
      },
      "source": [
        "\n",
        "Comment on your observations. Were we successfully able to group samples together without labels?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEdhT7vTG_Zy"
      },
      "source": [
        "(Enter Answer Here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVnLnybpHGPQ"
      },
      "source": [
        "## Exercise 3: Split the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIwnCnzJHMvJ"
      },
      "source": [
        "Use the train_test_split() function in sklearn (sklearn.model_selection.train_test_split ) to split the iris data set. Report the number of samples in both the train and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUH7YzyRHF9j"
      },
      "outputs": [],
      "source": [
        "import sklearn.model_selection.train_test_split as train_test_split\n",
        "\n",
        "#Split the dataset here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhTJYLW3Hbvi"
      },
      "source": [
        "What is the number of samples in the train set?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjbLBBaTHeFz"
      },
      "source": [
        "(Enter Answer Here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XV7IK3kHgYp"
      },
      "source": [
        "What is the number of samples in the test set?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JDe-sfIHjod"
      },
      "source": [
        "(Enter Answer Here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLxDvPQ5HmqM"
      },
      "source": [
        "## Exercise 4: K Nearest Neighbors\n",
        "\n",
        "Your Task: \n",
        "* Train a K-nearest neighbors (sklearn.neighbors.KNeighborsClassifier ) on the iris data.\n",
        "\n",
        "* Train your KNN when the n_neighbors parameter is 5. Report your train accuracy and test accuracy\n",
        "\n",
        "* Perform a grid search over the parameter n_neighbors over the range 1-20:\n",
        "\n",
        "* For each value of n_neighbors, fit a KNN and record your train and test accuracy\n",
        "\n",
        "* Create a plot showing the test/train accuracy over the n_neighbors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_E9-aOSH5Hb"
      },
      "outputs": [],
      "source": [
        "# Enter your code for Exercise 4 here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR5fbC_1IBOJ"
      },
      "source": [
        "What is your train accuracy and test accuracy for when the n_neighbors parameter is 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3LRr6jTIBCs"
      },
      "source": [
        "(Enter Answer Here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZ0N8tH77X"
      },
      "source": [
        "Discuss what you learn. How does train and test accuracy behave as you change the number of neighbors?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjrCp6VXH9yH"
      },
      "source": [
        "(Enter Answer Here)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
